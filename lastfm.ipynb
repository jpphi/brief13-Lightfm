{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coated-feature",
   "metadata": {},
   "source": [
    "## Resources:  \n",
    "* https://making.lyst.com/lightfm/docs/lightfm.html\n",
    "* https://towardsdatascience.com/how-to-build-a-movie-recommender-system-in-python-using-lightfm-8fa49d7cbe3b\n",
    "* https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civic-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "optional-chicago",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    totalUsers  totalPlays     avgPlays\n",
      "name                                                   \n",
      "Britney Spears             522     2393140  4584.559387\n",
      "Depeche Mode               282     1301308  4614.567376\n",
      "Lady Gaga                  611     1291387  2113.563011\n",
      "Christina Aguilera         407     1058405  2600.503686\n",
      "Paramore                   399      963449  2414.659148\n",
      "...                        ...         ...          ...\n",
      "Morris                       1           1     1.000000\n",
      "Eddie Kendricks              1           1     1.000000\n",
      "Excess Pressure              1           1     1.000000\n",
      "My Mine                      1           1     1.000000\n",
      "A.M. Architect               1           1     1.000000\n",
      "\n",
      "[17632 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "plays = pd.read_csv('datasets/user_artists.dat', sep='\\t')\n",
    "artists = pd.read_csv('datasets/artists.dat', sep='\\t', usecols=['id','name'])\n",
    "\n",
    "# Merge (fusionner) artist and user pref data\n",
    "ap = pd.merge(artists, plays, how=\"inner\", left_on=\"id\", right_on=\"artistID\")\n",
    "ap = ap.rename(columns={\"weight\": \"playCount\"})\n",
    "\n",
    "# Group artist by name\n",
    "artist_rank = ap.groupby(['name']) \\\n",
    "    .agg({'userID' : 'count', 'playCount' : 'sum'}) \\\n",
    "    .rename(columns={\"userID\" : 'totalUsers', \"playCount\" : \"totalPlays\"}) \\\n",
    "    .sort_values(['totalPlays'], ascending=False)\n",
    "\n",
    "artist_rank['avgPlays'] = artist_rank['totalPlays'] / artist_rank['totalUsers']\n",
    "print(artist_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lyric-intersection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "\n",
      "Plays info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92834 entries, 0 to 92833\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   userID    92834 non-null  int64\n",
      " 1   artistID  92834 non-null  int64\n",
      " 2   weight    92834 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 2.1 MB\n",
      "________________________________________________________________________________\n",
      "\n",
      "ap info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 92834 entries, 0 to 92833\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         92834 non-null  int64 \n",
      " 1   name       92834 non-null  object\n",
      " 2   userID     92834 non-null  int64 \n",
      " 3   artistID   92834 non-null  int64 \n",
      " 4   playCount  92834 non-null  int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 4.2+ MB\n",
      "________________________________________________________________________________\n",
      "\n",
      "artist info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17632 entries, 0 to 17631\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      17632 non-null  int64 \n",
      " 1   name    17632 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 275.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------------\n",
    "print(80*(\"_\"))\n",
    "print(\"\\nPlays info:\\n\")\n",
    "plays.info()\n",
    "print(80*(\"_\"))\n",
    "print(\"\\nap info:\\n\")\n",
    "ap.info()\n",
    "print(80*(\"_\"))\n",
    "print(\"\\nartist info:\\n\")\n",
    "artists.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "needed-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.28 %\n"
     ]
    }
   ],
   "source": [
    "# Merge into ap matrix\n",
    "ap = ap.join(artist_rank, on=\"name\", how=\"inner\") \\\n",
    "    .sort_values(['playCount'], ascending=False)\n",
    "\n",
    "# Preprocessing\n",
    "pc = ap.playCount\n",
    "play_count_scaled = (pc - pc.min()) / (pc.max() - pc.min())\n",
    "ap = ap.assign(playCountScaled=play_count_scaled)\n",
    "#print(ap)\n",
    "\n",
    "# Build a user-artist rating matrix \n",
    "ratings_df = ap.pivot(index='userID', columns='artistID', values='playCountScaled')\n",
    "ratings = ratings_df.fillna(0).values\n",
    "\n",
    "# Show sparsity . C'est plutôt une densité.... Indique le pourcentage de valeur non nul de la matrice. \n",
    "sparsity = float(len(ratings.nonzero()[0])) / (ratings.shape[0] * ratings.shape[1]) * 100\n",
    "print(f\"sparsity: {sparsity:.2f} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "activated-macintosh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1892, 17632)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "atomic-swimming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 92834 entries, 2800 to 63982\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               92834 non-null  int64  \n",
      " 1   name             92834 non-null  object \n",
      " 2   userID           92834 non-null  int64  \n",
      " 3   artistID         92834 non-null  int64  \n",
      " 4   playCount        92834 non-null  int64  \n",
      " 5   totalUsers       92834 non-null  int64  \n",
      " 6   totalPlays       92834 non-null  int64  \n",
      " 7   avgPlays         92834 non-null  float64\n",
      " 8   playCountScaled  92834 non-null  float64\n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 7.1+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2800        72\n",
       "35843      792\n",
       "27302      511\n",
       "8152       203\n",
       "26670      498\n",
       "         ...  \n",
       "38688      913\n",
       "32955      697\n",
       "71811     4988\n",
       "91319    17080\n",
       "63982     3201\n",
       "Name: artistID, Length: 92834, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ap.info())\n",
    "ap.artistID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "useful-keyboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating matrix shape (1892, 17632)\n"
     ]
    }
   ],
   "source": [
    "# Build a sparse matrix                      PEUT ON créer une matrice creuse coo directement ?\n",
    "X = csr_matrix(ratings)\n",
    "\n",
    "n_users, n_items = ratings_df.shape\n",
    "print(\"rating matrix shape\", ratings_df.shape)\n",
    "\n",
    "user_ids = ratings_df.index.values\n",
    "artist_names = ap.sort_values(\"artistID\")[\"name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "outdoor-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data references + train test\n",
    "Xcoo = X.tocoo()\n",
    "data = Dataset()\n",
    "data.fit(np.arange(n_users), np.arange(n_items))\n",
    "interactions, weights = data.build_interactions(zip(Xcoo.row, Xcoo.col, Xcoo.data)) \n",
    "train, test = random_train_test_split(interactions)\n",
    "\n",
    "# Ignore that (weight seems to be ignored...)\n",
    "#train = train_.tocsr()\n",
    "#test = test_.tocsr()\n",
    "#train[train==1] = X[train==1]\n",
    "#test[test==1] = X[test==1]\n",
    "\n",
    "# To be completed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "british-province",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fcc2f240550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "model.fit(train, epochs=10, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "reliable-cuisine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.37, test 0.13.\n",
      "AUC: train 0.96, test 0.86.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "upper-theory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Depeche Mode' 'Radiohead' 'Muse' ... 'Daville' 'Akira Senju/Akira Senju'\n",
      " 'International Observer']\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "scores = model.predict(0, np.arange(n_items))\n",
    "top_items = artist_names[np.argsort(-scores)]\n",
    "print(top_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "continued-jordan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1892, 17632)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape\n",
    "train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "brilliant-charles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Méthode warp:\n",
      "Precision: train 0.39, test 0.13.\n",
      "AUC: train 0.97, test 0.85.\n",
      "Recommandation:\n",
      "['Duran Duran' 'Depeche Mode' 'Radiohead' ... 'DOGinTheパラレルワールドオーケストラ'\n",
      " 'Donavon Hill' 'Envus']\n",
      "\n",
      "Méthode bpr:\n",
      "Precision: train 0.39, test 0.12.\n",
      "AUC: train 0.85, test 0.78.\n",
      "Recommandation:\n",
      "['Depeche Mode' 'Duran Duran' 'Pet Shop Boys' ... 'Ke$ha' 'Miley Cyrus'\n",
      " 'Avril Lavigne']\n",
      "\n",
      "Méthode warp-kos:\n",
      "Precision: train 0.34, test 0.12.\n",
      "AUC: train 0.89, test 0.82.\n",
      "Recommandation:\n",
      "['Depeche Mode' 'The Beatles' 'Madonna' ... 'Elveda Rumeli' 'Hatice'\n",
      " 'Styles & Breeze']\n",
      "\n",
      "Méthode logistic:\n",
      "Precision: train 0.21, test 0.07.\n",
      "AUC: train 0.89, test 0.81.\n",
      "Recommandation:\n",
      "['Lady Gaga' 'Britney Spears' 'Katy Perry' ... 'Secret Shine'\n",
      " 'Heinrich Ignaz Franz von Biber' 'やなわらばー']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_loss= [\"warp\", \"bpr\", \"warp-kos\", \"logistic\"]\n",
    "resultats= \"\"\n",
    "dictionnaire_param_loss= {}\n",
    "for ploss in param_loss:\n",
    "    tps_deb= time()\n",
    "\n",
    "    # Train\n",
    "    model = LightFM(learning_rate=0.05, loss= ploss)\n",
    "    model.fit(train, epochs=10, num_threads=2)\n",
    "\n",
    "    # Evaluate\n",
    "    train_precision = precision_at_k(model, train, k=10).mean()\n",
    "    test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "    train_auc = auc_score(model, train).mean()\n",
    "    test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "    \n",
    "    # Predict\n",
    "    scores = model.predict(0, np.arange(n_items))\n",
    "    top_items = artist_names[np.argsort(-scores)]\n",
    "    \n",
    "    tps_fin= time()\n",
    "\n",
    "\n",
    "    ch= \"Méthode \"+ ploss + \":\"+ f\"\\nPrecision: train {train_precision:.2f}, test {test_precision:.2f}.\" + \\\n",
    "    f\"\\nAUC: train {train_auc:.2f}, test {test_auc:.2f}.\" +\\\n",
    "    f\"\\nRecommandation:\\n{top_items}\" + \"\\n\\n\"\n",
    "    resultats+= ch\n",
    "    dictionnaire_param_loss[\"Méthode \" + ploss]={\"Précision train\": train_precision, \n",
    "                                                \"Précision test\": test_precision, \"AUC train\": train_auc, \n",
    "                                                \"AUC test\": test_auc, \"Temps\": tps_fin-tps_deb,\n",
    "                                                \"Recommandation\": top_items}\n",
    "\n",
    "print(resultats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-clock",
   "metadata": {},
   "source": [
    "### Le paramètre warp donne le meilleur résultat avec un écart important. Il sera donc choisi et fixer et les autres paramètres optimisés en utilisant GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-customer",
   "metadata": {},
   "source": [
    "Ressource: \n",
    "cours factorisation matrice + grid search CV\n",
    "    https://www.ethanrosenthal.com/2016/10/19/implicit-mf-part-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "meaning-midnight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Méthode warp': {'Précision train': 0.3878579,\n",
       "  'Précision test': 0.13297759,\n",
       "  'AUC train': 0.96636134,\n",
       "  'AUC test': 0.8542546,\n",
       "  'Temps': 36.927067279815674,\n",
       "  'Recommandation': array(['Duran Duran', 'Depeche Mode', 'Radiohead', ...,\n",
       "         'DOGinTheパラレルワールドオーケストラ', 'Donavon Hill', 'Envus'], dtype=object)},\n",
       " 'Méthode bpr': {'Précision train': 0.38531283,\n",
       "  'Précision test': 0.12406617,\n",
       "  'AUC train': 0.8501012,\n",
       "  'AUC test': 0.77569395,\n",
       "  'Temps': 37.497663497924805,\n",
       "  'Recommandation': array(['Depeche Mode', 'Duran Duran', 'Pet Shop Boys', ..., 'Ke$ha',\n",
       "         'Miley Cyrus', 'Avril Lavigne'], dtype=object)},\n",
       " 'Méthode warp-kos': {'Précision train': 0.34390244,\n",
       "  'Précision test': 0.12033084,\n",
       "  'AUC train': 0.88780546,\n",
       "  'AUC test': 0.8173134,\n",
       "  'Temps': 39.19034719467163,\n",
       "  'Recommandation': array(['Depeche Mode', 'The Beatles', 'Madonna', ..., 'Elveda Rumeli',\n",
       "         'Hatice', 'Styles & Breeze'], dtype=object)},\n",
       " 'Méthode logistic': {'Précision train': 0.20540828,\n",
       "  'Précision test': 0.06798293,\n",
       "  'AUC train': 0.88781804,\n",
       "  'AUC test': 0.8058057,\n",
       "  'Temps': 37.58233666419983,\n",
       "  'Recommandation': array(['Lady Gaga', 'Britney Spears', 'Katy Perry', ..., 'Secret Shine',\n",
       "         'Heinrich Ignaz Franz von Biber', 'やなわらばー'], dtype=object)}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionnaire_param_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "secure-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_learning_rate= np.arange(0.01, 0.2, 0.02)\n",
    "#param_epoch= np.arange(5,100,5)\n",
    "param_learning_rate= [0.01, 0.05, 0.1]\n",
    "param_epoch= [5, 10, 15]\n",
    "ploss= \"warp\"\n",
    "\n",
    "#print(param_learning_rate)\n",
    "#print(param_epoch)\n",
    "\n",
    "resultats= \"\"\n",
    "dictionnaire_learningrate_epoch= {}\n",
    "\n",
    "for learning_rate in [0.01, 0.05, 0.1]:\n",
    "    for epoch in param_epoch:\n",
    "        \n",
    "        tps_deb= time()\n",
    "\n",
    "        # Train\n",
    "        model = LightFM(learning_rate= learning_rate, loss= ploss)\n",
    "        model.fit(train, epochs= epoch, num_threads=2)\n",
    "\n",
    "        # Evaluate\n",
    "        train_precision = precision_at_k(model, train, k=10).mean()\n",
    "        test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "        train_auc = auc_score(model, train).mean()\n",
    "        test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "        # Predict\n",
    "        scores = model.predict(0, np.arange(n_items))\n",
    "        top_items = artist_names[np.argsort(-scores)]\n",
    "\n",
    "        tps_fin= time()\n",
    "\n",
    "\n",
    "        ch= \"Méthode \"+ ploss + \":\"+ f\"\\nPrecision: train {train_precision:.2f}, test {test_precision:.2f}.\" + \\\n",
    "        f\"\\nAUC: train {train_auc:.2f}, test {test_auc:.2f}.\" +\\\n",
    "        f\"\\nRecommandation:\\n{top_items}\" + \"\\n\\n\"\n",
    "        resultats+= ch\n",
    "        dictionnaire_learningrate_epoch[\"learning_rate\" + str(learning_rate) + \" epoch \" + str(epoch)]= \\\n",
    "            {\"Précision train\": train_precision, \"Précision test\": test_precision, \"AUC train\": train_auc, \\\n",
    "             \"AUC test\": test_auc, \"Temps\": tps_fin-tps_deb, \"Recommandation\": top_items}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "demanding-waste",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate0.01 epoch 5': {'Précision train': 0.23865324,\n",
       "  'Précision test': 0.082337245,\n",
       "  'AUC train': 0.8701217,\n",
       "  'AUC test': 0.79707277,\n",
       "  'Temps': 38.11367702484131,\n",
       "  'Recommandation': array(['Lady Gaga', 'The Beatles', 'Britney Spears', ...,\n",
       "         'Three 6 Mafia feat. Flo Rida, Sean Kingston & Tiësto',\n",
       "         'Mackenzie 1st', '7000$'], dtype=object)},\n",
       " 'learning_rate0.01 epoch 10': {'Précision train': 0.302386,\n",
       "  'Précision test': 0.10640342,\n",
       "  'AUC train': 0.89082557,\n",
       "  'AUC test': 0.809808,\n",
       "  'Temps': 36.344521284103394,\n",
       "  'Recommandation': array(['The Beatles', 'Coldplay', 'Radiohead', ..., 'Coresplittaz',\n",
       "         'Shiva in Exile', 'Deborah Harry'], dtype=object)},\n",
       " 'learning_rate0.01 epoch 15': {'Précision train': 0.21399789,\n",
       "  'Précision test': 0.070437565,\n",
       "  'AUC train': 0.89287406,\n",
       "  'AUC test': 0.8102775,\n",
       "  'Temps': 36.31895351409912,\n",
       "  'Recommandation': array(['Lady Gaga', 'Britney Spears', 'Katy Perry', ...,\n",
       "         'Shaik Abu Baker Al-Shatiri', 'Juju', 'Whitehouse'], dtype=object)},\n",
       " 'learning_rate0.05 epoch 5': {'Précision train': 0.3624072,\n",
       "  'Précision test': 0.12502669,\n",
       "  'AUC train': 0.9399554,\n",
       "  'AUC test': 0.8414501,\n",
       "  'Temps': 33.748095750808716,\n",
       "  'Recommandation': array(['Radiohead', 'The Beatles', 'Depeche Mode', ..., 'Сэт',\n",
       "         'Tommy heavenly6', 'And'], dtype=object)},\n",
       " 'learning_rate0.05 epoch 10': {'Précision train': 0.3924708,\n",
       "  'Précision test': 0.1378335,\n",
       "  'AUC train': 0.96799636,\n",
       "  'AUC test': 0.8562735,\n",
       "  'Temps': 34.35528302192688,\n",
       "  'Recommandation': array(['Depeche Mode', 'Pet Shop Boys', 'Duran Duran', ...,\n",
       "         \"Fuck...I'm Dead\", 'ＬｕＬｕ', \"Youssou N'Dour\"], dtype=object)},\n",
       " 'learning_rate0.05 epoch 15': {'Précision train': 0.404719,\n",
       "  'Précision test': 0.13847385,\n",
       "  'AUC train': 0.97680974,\n",
       "  'AUC test': 0.8620883,\n",
       "  'Temps': 35.72469687461853,\n",
       "  'Recommandation': array(['Duran Duran', 'David Bowie', 'Depeche Mode', ...,\n",
       "         'Alice Coltrane', 'Dub Syndicate', 'Fred Nukes'], dtype=object)},\n",
       " 'learning_rate0.1 epoch 5': {'Précision train': 0.35222697,\n",
       "  'Précision test': 0.114354335,\n",
       "  'AUC train': 0.9664916,\n",
       "  'AUC test': 0.8328918,\n",
       "  'Temps': 33.59630727767944,\n",
       "  'Recommandation': array(['Radiohead', 'Depeche Mode', 'Klaxons', ..., 'Angelis',\n",
       "         'Anjos De Resgate', 'Dream Evil'], dtype=object)},\n",
       " 'learning_rate0.1 epoch 10': {'Précision train': 0.36723223,\n",
       "  'Précision test': 0.117022425,\n",
       "  'AUC train': 0.9834791,\n",
       "  'AUC test': 0.84219104,\n",
       "  'Temps': 33.559890031814575,\n",
       "  'Recommandation': array(['Depeche Mode', 'The Beatles', 'Radiohead', ...,\n",
       "         'Dio - Distraught Overlord', 'The Easybeats', 'Adriana'],\n",
       "        dtype=object)},\n",
       " 'learning_rate0.1 epoch 15': {'Précision train': 0.38637328,\n",
       "  'Précision test': 0.12358592,\n",
       "  'AUC train': 0.98801726,\n",
       "  'AUC test': 0.8461067,\n",
       "  'Temps': 34.80497121810913,\n",
       "  'Recommandation': array(['Pet Shop Boys', 'a-ha', 'New Order', ..., 'Eleni Karaindrou',\n",
       "         'CIRЯUS', 'Logistics'], dtype=object)}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionnaire_learningrate_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "changing-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "vietnamese-wright",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Méthode warp:\n",
      "Precision: train 0.38, test 0.13.\n",
      "AUC: train 0.97, test 0.86.\n",
      "Recommandation:\n",
      "['Coldplay' 'Muse' 'The Killers' ... 'Ekaros' 'The Easybeats' 'Swift Guad']\n",
      "\n",
      "Méthode bpr:\n",
      "Precision: train 0.37, test 0.12.\n",
      "AUC: train 0.85, test 0.78.\n",
      "Recommandation:\n",
      "['Coldplay' 'Depeche Mode' 'Muse' ... 'Rihanna' 'Ashley Tisdale'\n",
      " 'Miley Cyrus']\n",
      "\n",
      "Méthode warp-kos:\n",
      "Precision: train 0.35, test 0.13.\n",
      "AUC: train 0.89, test 0.82.\n",
      "Recommandation:\n",
      "['Pet Shop Boys' 'Madonna' 'Goldfrapp' ... 'Centr' 'Ассаи' 'True Star']\n",
      "\n",
      "Méthode logistic:\n",
      "Precision: train 0.20, test 0.07.\n",
      "AUC: train 0.89, test 0.81.\n",
      "Recommandation:\n",
      "['Lady Gaga' 'Britney Spears' 'Rihanna' ... 'Patrizio Buanne'\n",
      " 'The Union Underground' 'Bootsy Collins']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(resultats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "employed-glass",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1892, 17632)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM()\n",
    "param={\"no_components\":[10,25,50,75,100,150,200], \"loss\": ['warp'], \"learning_rate\":[0.05, 0.07]}\n",
    "\n",
    "\n",
    "#train_csr = train_set.tocsr()\n",
    "#test_set = test_set.tocsr()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-victim",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "italic-lincoln",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "veterinary-bench",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "conscious-pulse",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'auc_score' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[0;34m(scoring)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                 \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'auc_score'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-7f4e43a9650f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         scorers, self.multimetric_ = _check_multimetric_scoring(\n\u001b[0m\u001b[1;32m    655\u001b[0m             self.estimator, scoring=self.scoring)\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[0;34m(estimator, scoring)\u001b[0m\n\u001b[1;32m    473\u001b[0m     if callable(scoring) or scoring is None or isinstance(scoring,\n\u001b[1;32m    474\u001b[0m                                                           str):\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    403\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;31m# Heuristic to ensure user has not passed a metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[0;34m(scoring)\u001b[0m\n\u001b[1;32m    360\u001b[0m                 \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             raise ValueError('%r is not a valid scoring value. '\n\u001b[0m\u001b[1;32m    363\u001b[0m                              \u001b[0;34m'Use sorted(sklearn.metrics.SCORERS.keys()) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                              'to get valid options.' % scoring)\n",
      "\u001b[0;31mValueError\u001b[0m: 'auc_score' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options."
     ]
    }
   ],
   "source": [
    "grid.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-multiple",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-chance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-pacific",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-development",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "exterior-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display \n",
    "\n",
    "pd.options.display.max_columns = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "computational-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "standing-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Méthode warp:\n",
      "Precision: train 0.38, test 0.13.\n",
      "AUC: train 0.97, test 0.86.\n",
      "Recommandation:\n",
      "['Coldplay' 'Muse' 'The Killers' ... 'Ekaros' 'The Easybeats' 'Swift Guad']\n",
      "\n",
      "Méthode bpr:\n",
      "Precision: train 0.37, test 0.12.\n",
      "AUC: train 0.85, test 0.78.\n",
      "Recommandation:\n",
      "['Coldplay' 'Depeche Mode' 'Muse' ... 'Rihanna' 'Ashley Tisdale'\n",
      " 'Miley Cyrus']\n",
      "\n",
      "Méthode warp-kos:\n",
      "Precision: train 0.35, test 0.13.\n",
      "AUC: train 0.89, test 0.82.\n",
      "Recommandation:\n",
      "['Pet Shop Boys' 'Madonna' 'Goldfrapp' ... 'Centr' 'Ассаи' 'True Star']\n",
      "\n",
      "Méthode logistic:\n",
      "Precision: train 0.20, test 0.07.\n",
      "AUC: train 0.89, test 0.81.\n",
      "Recommandation:\n",
      "['Lady Gaga' 'Britney Spears' 'Rihanna' ... 'Patrizio Buanne'\n",
      " 'The Union Underground' 'Bootsy Collins']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(resultats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-services",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-foster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "precise-pointer",
   "metadata": {},
   "source": [
    "\n",
    "# Recommander Systems\n",
    "\n",
    "Construire, comprendre et tuner un système de recommandation.\n",
    "\n",
    "# Description\n",
    "\n",
    "## Familarisation\n",
    "\n",
    "Les systèmes de recommandations sont utilisé traditionnellement et comme le nom l'indique pour recommander du contenu à des utilisateurs.\n",
    "Par exemple pour recommander un film à des utilisateurs en fonctions de ceux qu'ils ont vue, ou de la musique, ou des vidéos ou encore implémenter des fonctionnalités \"more like this\".\n",
    "\n",
    "Nous allons commencer par suivre et reproduire les étapes de ce tuto: \n",
    "\n",
    "*  https://www.datacamp.com/community/tutorials/recommender-systems-python\n",
    "\n",
    "En assumant que vous avez peu de RAM, nous allons nous arrêter au moment de calculer la  `compute_sim` variable.\n",
    "\n",
    "\n",
    "**step1 : simple recommander**\n",
    "Quelle est la complexité en mémoire de cette opération ?\n",
    "(utiliser cosine_similarity qui utilise moins de mémoire (quand même 8Go, possible sur collab)\n",
    "Cela rentre t'il sur votre machine ?\n",
    "\n",
    "Qu'essaye de faire l'auteur avec ce calcul ?\n",
    "Comment pouvons-nous contourner ce problème ?\n",
    "\n",
    "\n",
    "**step2 : content based recommander**\n",
    "\n",
    "implémenter la deuxiéme partie en évitant le produit de matrice.\n",
    "\n",
    "**step3 : amélioration**\n",
    "\n",
    "coder les 2 améliorations :\n",
    "1. Introduce a popularity filter: this recommender would take the 30 most similar movies, calculate the weighted ratings (using the IMDB formula from above), sort movies based on this rating, and return the top 10 movies.\n",
    "2. Use the PCA to improve the speed of your similarity search with 100 components. Does the result are coherent.\n",
    "\n",
    "\n",
    "## LastFM Project\n",
    "\n",
    "M. Pontier vous contact pour l'aider à construire un système de recommandation. Il dispose d'une base de données comportant des données concernant ses utilisateurs (anonymisé) contenant les artistes qu'ils écoutent sur sa plateforme ainsi que le nombre d'écoutes. Monsieur pontier souhaite recommander à ses utilisateur  des artistes qu'il n'ont pas encore écoutés, et cela en fonction de leurs préférences musicale.\n",
    "\n",
    "Monsieur pontier souhaite utiliser la librairie Lightfm, avec laquelle il a déjà un driver permettant de charger ses données qu'il vous fournit, un vrai bonus.\n",
    "Monsieur Pontier à pu voir que la documentation comporte plusieurs modèle, il souhaite évaluer les modèle sur une jeux de train/test et utiliser le meilleurs modéle.\n",
    "\n",
    "Pour l'évaluation, il souhaite comparer la mesure AUC, la précision et le rappel (visiter la documentation de Lightfm), qui devront être présenté dans un tableau.\n",
    "\n",
    "\n",
    "#### Bonus 1\n",
    "\n",
    "Comparer les résulats de l'AUC avec le meilleurs modéle de lightfm et une PCA (TruncatedSDV).\n",
    "\n",
    "\n",
    "#### Bonus 2\n",
    "\n",
    "L'apprentissage devant être le plus rapide possible tout en obtenant les meilleurs résultats, il vous est demandé de trouver le nombre d'itération permettant d'atteindre la convergence de 95% de la valeur maximal d'AUC sur le jeux de test.\n",
    "\n",
    "\n",
    "### Veille\n",
    "\n",
    "Quelle système de recommandation allez vous mettre en place ?\n",
    "\n",
    "Qu'est ce que Lightfm ?\n",
    "\n",
    "Qu'est ce un système de recommandation dit à \"implicit feedback\" ? Et a \"explicit feedback ?\n",
    "\n",
    "\n",
    "### Ressources: \n",
    "\n",
    "* LightFM: https://github.com/lyst/lightfm\n",
    "* Jeux de données Last.fm : https://grouplens.org/datasets/hetrec-2011/\n",
    "* https://towardsdatascience.com/recommendation-system-in-python-lightfm-61c85010ce17\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-bridal",
   "metadata": {},
   "source": [
    "# Bout de code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "structural-breakdown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Artiste  id\n",
      "0    toto  10\n",
      "1    titi  11\n",
      "2    tutu  12\n",
      "3    tyty  13\n",
      "4    tata  14\n",
      "5    tete  15\n",
      "  Utilisateur  id\n",
      "0      d2toto  10\n",
      "1      d2titi  11\n",
      "2      d2tutu  12\n",
      "3      d2tyty  13\n",
      "4      d2tata  14\n",
      "5      d2tete  15\n"
     ]
    }
   ],
   "source": [
    "data1= np.array([[\"toto\",\"titi\",\"tutu\",\"tyty\",\"tata\",\"tete\"],[10,11,12,13,14,15]]).T\n",
    "df1= pd.DataFrame(data1, columns=[\"Artiste\",\"id\"])\n",
    "print(df1)\n",
    "data2= np.array([[\"d2toto\",\"d2titi\",\"d2tutu\",\"d2tyty\",\"d2tata\",\"d2tete\"],[10,11,12,13,14,15]]).T\n",
    "df2= pd.DataFrame(data2, columns=[\"Utilisateur\",\"id\"])\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "following-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artiste</th>\n",
       "      <th>id</th>\n",
       "      <th>Utilisateur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toto</td>\n",
       "      <td>10</td>\n",
       "      <td>d2toto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>titi</td>\n",
       "      <td>11</td>\n",
       "      <td>d2titi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tutu</td>\n",
       "      <td>12</td>\n",
       "      <td>d2tutu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tyty</td>\n",
       "      <td>13</td>\n",
       "      <td>d2tyty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tata</td>\n",
       "      <td>14</td>\n",
       "      <td>d2tata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tete</td>\n",
       "      <td>15</td>\n",
       "      <td>d2tete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Artiste  id Utilisateur\n",
       "0    toto  10      d2toto\n",
       "1    titi  11      d2titi\n",
       "2    tutu  12      d2tutu\n",
       "3    tyty  13      d2tyty\n",
       "4    tata  14      d2tata\n",
       "5    tete  15      d2tete"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1df2 = pd.merge(df1, df2, how=\"inner\")\n",
    "df1df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-stylus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
