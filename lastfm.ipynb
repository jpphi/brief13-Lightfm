{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "protected-pottery",
   "metadata": {},
   "source": [
    "## Resources:  \n",
    "* https://making.lyst.com/lightfm/docs/lightfm.html\n",
    "* https://towardsdatascience.com/how-to-build-a-movie-recommender-system-in-python-using-lightfm-8fa49d7cbe3b\n",
    "* https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "surface-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "from scipy.sparse import csr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "impossible-plate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    totalUsers  totalPlays     avgPlays\n",
      "name                                                   \n",
      "Britney Spears             522     2393140  4584.559387\n",
      "Depeche Mode               282     1301308  4614.567376\n",
      "Lady Gaga                  611     1291387  2113.563011\n",
      "Christina Aguilera         407     1058405  2600.503686\n",
      "Paramore                   399      963449  2414.659148\n",
      "...                        ...         ...          ...\n",
      "Morris                       1           1     1.000000\n",
      "Eddie Kendricks              1           1     1.000000\n",
      "Excess Pressure              1           1     1.000000\n",
      "My Mine                      1           1     1.000000\n",
      "A.M. Architect               1           1     1.000000\n",
      "\n",
      "[17632 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "plays = pd.read_csv('datasets/user_artists.dat', sep='\\t')\n",
    "artists = pd.read_csv('datasets/artists.dat', sep='\\t', usecols=['id','name'])\n",
    "\n",
    "# Merge (fusionner) artist and user pref data\n",
    "ap = pd.merge(artists, plays, how=\"inner\", left_on=\"id\", right_on=\"artistID\")\n",
    "ap = ap.rename(columns={\"weight\": \"playCount\"})\n",
    "\n",
    "# Group artist by name\n",
    "artist_rank = ap.groupby(['name']) \\\n",
    "    .agg({'userID' : 'count', 'playCount' : 'sum'}) \\\n",
    "    .rename(columns={\"userID\" : 'totalUsers', \"playCount\" : \"totalPlays\"}) \\\n",
    "    .sort_values(['totalPlays'], ascending=False)\n",
    "\n",
    "artist_rank['avgPlays'] = artist_rank['totalPlays'] / artist_rank['totalUsers']\n",
    "print(artist_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "excited-citation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "\n",
      "Plays info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92834 entries, 0 to 92833\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   userID    92834 non-null  int64\n",
      " 1   artistID  92834 non-null  int64\n",
      " 2   weight    92834 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 2.1 MB\n",
      "________________________________________________________________________________\n",
      "\n",
      "ap info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 92834 entries, 0 to 92833\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         92834 non-null  int64 \n",
      " 1   name       92834 non-null  object\n",
      " 2   userID     92834 non-null  int64 \n",
      " 3   artistID   92834 non-null  int64 \n",
      " 4   playCount  92834 non-null  int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 4.2+ MB\n",
      "________________________________________________________________________________\n",
      "\n",
      "artist info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17632 entries, 0 to 17631\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      17632 non-null  int64 \n",
      " 1   name    17632 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 275.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------------\n",
    "print(80*(\"_\"))\n",
    "print(\"\\nPlays info:\\n\")\n",
    "plays.info()\n",
    "print(80*(\"_\"))\n",
    "print(\"\\nap info:\\n\")\n",
    "ap.info()\n",
    "print(80*(\"_\"))\n",
    "print(\"\\nartist info:\\n\")\n",
    "artists.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-request",
   "metadata": {},
   "source": [
    "## Normalisation des données  \n",
    "  \n",
    "On n'utilisera la ligne:  \n",
    "ap.playCount= np.log(ap.playCount + 0.1) # + 0.1 pour éviter les '0' (log(1)= 0)  \n",
    "  \n",
    "Résultat:  \n",
    "\n",
    "Normalisation avec échelle Logarithmique  \n",
    "['Depeche Mode' 'David Bowie' 'The Beatles' **'New Order'** **'Duran Duran'** 'The Cure' **'Pet Shop Boys'** **Radiohead'** **'Erasure'** **'Björk'**]  \n",
    "   \n",
    "Normalisation sans échelle logarithmique  \n",
    "['Depeche Mode' 'David Bowie' 'Daft Punk' 'Queen' 'The Beatles' 'Coldplay' 'Madonna' 'Muse' 'Lady Gaga' 'The Cure']  \n",
    "  \n",
    "**En gras les différences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "statistical-standing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.28 %\n"
     ]
    }
   ],
   "source": [
    "# Merge into ap matrix\n",
    "ap = ap.join(artist_rank, on=\"name\", how=\"inner\").sort_values(['playCount'], ascending=False)\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "# On teste ici une approche logarithmique pour éviter l'effet \"lady gaga\" recommandé pour tous \n",
    "ap.playCount= np.log(ap.playCount + 0.1) # + 0.1 pour éviter les '0' (log(1)= 0)\n",
    "\n",
    "pc = ap.playCount\n",
    "play_count_scaled = (pc - pc.min()) / (pc.max() - pc.min())\n",
    "ap = ap.assign(playCountScaled=play_count_scaled)\n",
    "#print(ap)\n",
    "\n",
    "# Build a user-artist rating matrix \n",
    "ratings_df = ap.pivot(index='userID', columns='artistID', values='playCountScaled')\n",
    "ratings = ratings_df.fillna(0).values\n",
    "\n",
    "# Show sparsity . C'est plutôt une densité.... Indique le pourcentage de valeur non nul de la matrice. \n",
    "sparsity = float(len(ratings.nonzero()[0])) / (ratings.shape[0] * ratings.shape[1]) * 100\n",
    "print(f\"sparsity: {sparsity:.2f} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "floating-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings.shape\n",
    "#ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sudden-heaven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 92834 entries, 2800 to 63982\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               92834 non-null  int64  \n",
      " 1   name             92834 non-null  object \n",
      " 2   userID           92834 non-null  int64  \n",
      " 3   artistID         92834 non-null  int64  \n",
      " 4   playCount        92834 non-null  float64\n",
      " 5   totalUsers       92834 non-null  int64  \n",
      " 6   totalPlays       92834 non-null  int64  \n",
      " 7   avgPlays         92834 non-null  float64\n",
      " 8   playCountScaled  92834 non-null  float64\n",
      "dtypes: float64(3), int64(5), object(1)\n",
      "memory usage: 7.1+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2800        72\n",
       "35843      792\n",
       "27302      511\n",
       "8152       203\n",
       "26670      498\n",
       "         ...  \n",
       "38688      913\n",
       "32955      697\n",
       "71811     4988\n",
       "91319    17080\n",
       "63982     3201\n",
       "Name: artistID, Length: 92834, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ap.info())\n",
    "ap.artistID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "technological-decline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating matrix shape (1892, 17632)\n"
     ]
    }
   ],
   "source": [
    "# Build a sparse matrix                      PEUT ON créer une matrice creuse coo directement ?\n",
    "X = csr_matrix(ratings)\n",
    "\n",
    "n_users, n_items = ratings_df.shape\n",
    "print(\"rating matrix shape\", ratings_df.shape)\n",
    "\n",
    "user_ids = ratings_df.index.values\n",
    "artist_names = ap.sort_values(\"artistID\")[\"name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "identified-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data references + train test\n",
    "Xcoo = X.tocoo()\n",
    "data = Dataset()\n",
    "data.fit(np.arange(n_users), np.arange(n_items))\n",
    "interactions, weights = data.build_interactions(zip(Xcoo.row, Xcoo.col, Xcoo.data)) \n",
    "train, test = random_train_test_split(interactions)\n",
    "\n",
    "# Ignore that (weight seems to be ignored...)\n",
    "#train = train_.tocsr()\n",
    "#test = test_.tocsr()\n",
    "#train[train==1] = X[train==1]\n",
    "#test[test==1] = X[test==1]\n",
    "\n",
    "# To be completed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "optional-score",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f104b9afb20>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "model.fit(train, epochs=10, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "academic-combining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.39, test 0.13.\n",
      "AUC: train 0.97, test 0.86.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "collect-photography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Beatles' 'Depeche Mode' 'Pet Shop Boys' 'Madonna' 'a-ha' 'Coldplay'\n",
      " 'Michael Jackson' 'Duran Duran' 'New Order' 'Queen']\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "scores = model.predict(0, np.arange(n_items))\n",
    "top_items = artist_names[np.argsort(-scores)]\n",
    "print(top_items[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "independent-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.shape\n",
    "#train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "massive-carbon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Méthode warp:\n",
      "Precision: train 0.38, test 0.13.\n",
      "AUC: train 0.96, test 0.85.\n",
      "Recommandation:\n",
      "['Madonna' 'Michael Jackson' 'Lady Gaga' ... 'Texas in July' 'that dog.'\n",
      " 'Pipedown']\n",
      "\n",
      "Méthode bpr:\n",
      "Precision: train 0.36, test 0.12.\n",
      "AUC: train 0.85, test 0.78.\n",
      "Recommandation:\n",
      "['Depeche Mode' 'Madonna' 'New Order' ... 'Miley Cyrus' 'Ke$ha'\n",
      " 'Linkin Park']\n",
      "\n",
      "Méthode warp-kos:\n",
      "Precision: train 0.34, test 0.12.\n",
      "AUC: train 0.89, test 0.82.\n",
      "Recommandation:\n",
      "['David Bowie' 'The Beatles' 'Björk' ... 'Nyze' 'Berlins Most Wanted'\n",
      " 'Hostage Calm']\n",
      "\n",
      "Méthode logistic:\n",
      "Precision: train 0.20, test 0.07.\n",
      "AUC: train 0.89, test 0.81.\n",
      "Recommandation:\n",
      "['Lady Gaga' 'Britney Spears' 'Rihanna' ... 'Edan' 'Estudio Base'\n",
      " 'Pleq & Chihiro']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_loss= [\"warp\", \"bpr\", \"warp-kos\", \"logistic\"]\n",
    "resultats= \"\"\n",
    "dictionnaire_param_loss= {}\n",
    "for ploss in param_loss:\n",
    "    tps_deb= time()\n",
    "\n",
    "    # Train\n",
    "    model = LightFM(learning_rate=0.05, loss= ploss)\n",
    "    model.fit(train, epochs=10, num_threads=2)\n",
    "\n",
    "    # Evaluate\n",
    "    train_precision = precision_at_k(model, train, k=10).mean()\n",
    "    test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "    train_auc = auc_score(model, train).mean()\n",
    "    test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "    \n",
    "    # Predict\n",
    "    scores = model.predict(0, np.arange(n_items))\n",
    "    top_items = artist_names[np.argsort(-scores)]\n",
    "    \n",
    "    tps_fin= time()\n",
    "\n",
    "\n",
    "    ch= \"Méthode \"+ ploss + \":\"+ f\"\\nPrecision: train {train_precision:.2f}, test {test_precision:.2f}.\" + \\\n",
    "    f\"\\nAUC: train {train_auc:.2f}, test {test_auc:.2f}.\" +\\\n",
    "    f\"\\nRecommandation:\\n{top_items}\" + \"\\n\\n\"\n",
    "    resultats+= ch\n",
    "    dictionnaire_param_loss[\"Méthode \" + ploss]={\"Précision train\": train_precision, \n",
    "                                                \"Précision test\": test_precision, \"AUC train\": train_auc, \n",
    "                                                \"AUC test\": test_auc, \"Temps\": tps_fin-tps_deb,\n",
    "                                                \"Recommandation\": top_items}\n",
    "\n",
    "print(resultats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-naples",
   "metadata": {},
   "source": [
    "### Le paramètre warp donne le meilleur résultat avec un écart important. Il sera donc choisi et fixer. Les autres paramètres seront optimisés en utilisant GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-stuff",
   "metadata": {},
   "source": [
    "Ressource: \n",
    "cours factorisation matrice + grid search CV\n",
    "    https://www.ethanrosenthal.com/2016/10/19/implicit-mf-part-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acute-discount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Méthode warp': {'Précision train': 0.37582183,\n",
       "  'Précision test': 0.1298077,\n",
       "  'AUC train': 0.9628738,\n",
       "  'AUC test': 0.8549985,\n",
       "  'Temps': 9.884975671768188,\n",
       "  'Recommandation': array(['Madonna', 'Michael Jackson', 'Lady Gaga', ..., 'Texas in July',\n",
       "         'that dog.', 'Pipedown'], dtype=object)},\n",
       " 'Méthode bpr': {'Précision train': 0.36436903,\n",
       "  'Précision test': 0.121634625,\n",
       "  'AUC train': 0.85374516,\n",
       "  'AUC test': 0.7810532,\n",
       "  'Temps': 10.457010746002197,\n",
       "  'Recommandation': array(['Depeche Mode', 'Madonna', 'New Order', ..., 'Miley Cyrus',\n",
       "         'Ke$ha', 'Linkin Park'], dtype=object)},\n",
       " 'Méthode warp-kos': {'Précision train': 0.34008482,\n",
       "  'Précision test': 0.12179488,\n",
       "  'AUC train': 0.8870051,\n",
       "  'AUC test': 0.8193632,\n",
       "  'Temps': 10.963048934936523,\n",
       "  'Recommandation': array(['David Bowie', 'The Beatles', 'Björk', ..., 'Nyze',\n",
       "         'Berlins Most Wanted', 'Hostage Calm'], dtype=object)},\n",
       " 'Méthode logistic': {'Précision train': 0.19718982,\n",
       "  'Précision test': 0.06917736,\n",
       "  'AUC train': 0.8873434,\n",
       "  'AUC test': 0.80964786,\n",
       "  'Temps': 9.864659547805786,\n",
       "  'Recommandation': array(['Lady Gaga', 'Britney Spears', 'Rihanna', ..., 'Edan',\n",
       "         'Estudio Base', 'Pleq & Chihiro'], dtype=object)}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionnaire_param_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "entertaining-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_learning_rate= np.arange(0.01, 0.2, 0.02)\n",
    "#param_epoch= np.arange(5,100,5)\n",
    "param_learning_rate= [0.01, 0.05, 0.1]\n",
    "param_epoch= [5, 10, 15]\n",
    "ploss= \"warp\"\n",
    "\n",
    "#print(param_learning_rate)\n",
    "#print(param_epoch)\n",
    "\n",
    "resultats= \"\"\n",
    "dictionnaire_learningrate_epoch= {}\n",
    "\n",
    "for learning_rate in [0.01, 0.05, 0.1]:\n",
    "    for epoch in param_epoch:\n",
    "        \n",
    "        tps_deb= time()\n",
    "\n",
    "        # Train\n",
    "        model = LightFM(learning_rate= learning_rate, loss= ploss)\n",
    "        model.fit(train, epochs= epoch, num_threads=2)\n",
    "\n",
    "        # Evaluate\n",
    "        train_precision = precision_at_k(model, train, k=10).mean()\n",
    "        test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "        train_auc = auc_score(model, train).mean()\n",
    "        test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "        # Predict\n",
    "        scores = model.predict(0, np.arange(n_items))\n",
    "        top_items = artist_names[np.argsort(-scores)]\n",
    "\n",
    "        tps_fin= time()\n",
    "\n",
    "\n",
    "        ch= \"Méthode \"+ ploss + \":\"+ f\"\\nPrecision: train {train_precision:.2f}, test {test_precision:.2f}.\" + \\\n",
    "        f\"\\nAUC: train {train_auc:.2f}, test {test_auc:.2f}.\" +\\\n",
    "        f\"\\nRecommandation:\\n{top_items[:10]}\" + \"\\n\\n\"\n",
    "        resultats+= ch\n",
    "        dictionnaire_learningrate_epoch[\"learning_rate\" + str(learning_rate) + \" epoch \" + str(epoch)]= \\\n",
    "            {\"Précision train\": train_precision, \"Précision test\": test_precision, \"AUC train\": train_auc, \\\n",
    "             \"AUC test\": test_auc, \"Temps\": tps_fin-tps_deb, \"Recommandation\": top_items[:10]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "accurate-dominant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate0.01 epoch 5': {'Précision train': 0.25784728,\n",
       "  'Précision test': 0.090384625,\n",
       "  'AUC train': 0.8703303,\n",
       "  'AUC test': 0.8024738,\n",
       "  'Temps': 10.245213031768799,\n",
       "  'Recommandation': array(['Lady Gaga', 'Britney Spears', 'Rihanna', 'Katy Perry', 'Madonna',\n",
       "         'Paramore', 'The Beatles', 'Avril Lavigne', 'Christina Aguilera',\n",
       "         'Beyoncé'], dtype=object)},\n",
       " 'learning_rate0.01 epoch 10': {'Précision train': 0.28054082,\n",
       "  'Précision test': 0.098023504,\n",
       "  'AUC train': 0.887231,\n",
       "  'AUC test': 0.80903226,\n",
       "  'Temps': 10.064653158187866,\n",
       "  'Recommandation': array(['Lady Gaga', 'Britney Spears', 'The Beatles', 'Rihanna', 'Muse',\n",
       "         'Katy Perry', 'Madonna', 'Christina Aguilera', 'Paramore',\n",
       "         'Avril Lavigne'], dtype=object)},\n",
       " 'learning_rate0.01 epoch 15': {'Précision train': 0.2828738,\n",
       "  'Précision test': 0.09476496,\n",
       "  'AUC train': 0.8960393,\n",
       "  'AUC test': 0.81631577,\n",
       "  'Temps': 10.277898788452148,\n",
       "  'Recommandation': array(['Lady Gaga', 'Britney Spears', 'Madonna', 'Rihanna', 'The Beatles',\n",
       "         'Beyoncé', 'Christina Aguilera', 'Katy Perry', 'Avril Lavigne',\n",
       "         'Muse'], dtype=object)},\n",
       " 'learning_rate0.05 epoch 5': {'Précision train': 0.35212088,\n",
       "  'Précision test': 0.12259615,\n",
       "  'AUC train': 0.940019,\n",
       "  'AUC test': 0.84453136,\n",
       "  'Temps': 10.235884189605713,\n",
       "  'Recommandation': array(['Muse', 'Depeche Mode', 'The Beatles', 'Coldplay', 'The Cure',\n",
       "         'The Killers', 'Radiohead', 'Green Day', 'Arctic Monkeys',\n",
       "         'Madonna'], dtype=object)},\n",
       " 'learning_rate0.05 epoch 10': {'Précision train': 0.3906151,\n",
       "  'Précision test': 0.13798077,\n",
       "  'AUC train': 0.96736825,\n",
       "  'AUC test': 0.8606081,\n",
       "  'Temps': 11.957024335861206,\n",
       "  'Recommandation': array(['Madonna', 'Depeche Mode', 'Michael Jackson', 'Duran Duran',\n",
       "         'a-ha', 'Lady Gaga', 'Pet Shop Boys', 'New Order', 'Björk',\n",
       "         'The Beatles'], dtype=object)},\n",
       " 'learning_rate0.05 epoch 15': {'Précision train': 0.4016967,\n",
       "  'Précision test': 0.13851497,\n",
       "  'AUC train': 0.97656006,\n",
       "  'AUC test': 0.8660231,\n",
       "  'Temps': 10.265170335769653,\n",
       "  'Recommandation': array(['The Beatles', 'Madonna', 'Radiohead', 'Depeche Mode', 'Björk',\n",
       "         'Daft Punk', 'Muse', 'U2', 'Michael Jackson', 'Goldfrapp'],\n",
       "        dtype=object)},\n",
       " 'learning_rate0.1 epoch 5': {'Précision train': 0.3480382,\n",
       "  'Précision test': 0.11565172,\n",
       "  'AUC train': 0.96538705,\n",
       "  'AUC test': 0.8351683,\n",
       "  'Temps': 9.622056484222412,\n",
       "  'Recommandation': array(['The Cure', 'Radiohead', 'Sigur Rós', 'Depeche Mode', 'New Order',\n",
       "         'Dave Gahan', 'Björk', 'a-ha', 'The Beatles', 'Camouflage'],\n",
       "        dtype=object)},\n",
       " 'learning_rate0.1 epoch 10': {'Précision train': 0.37545067,\n",
       "  'Précision test': 0.122435905,\n",
       "  'AUC train': 0.9834084,\n",
       "  'AUC test': 0.8440251,\n",
       "  'Temps': 9.580250024795532,\n",
       "  'Recommandation': array(['Depeche Mode', 'a-ha', 'The Beatles', 'Pet Shop Boys', 'Placebo',\n",
       "         'Bauhaus', 'Led Zeppelin', 'The Cure', 'Duran Duran', 'Nirvana'],\n",
       "        dtype=object)},\n",
       " 'learning_rate0.1 epoch 15': {'Précision train': 0.37672323,\n",
       "  'Précision test': 0.12361112,\n",
       "  'AUC train': 0.98758894,\n",
       "  'AUC test': 0.84682965,\n",
       "  'Temps': 9.732582807540894,\n",
       "  'Recommandation': array(['Röyksopp', 'Madonna', 'Orchestral Manoeuvres in the Dark',\n",
       "         'Erasure', 'Glee Cast', 'Dido', 'Depeche Mode', 'Bat for Lashes',\n",
       "         'Pet Shop Boys', 'Goldfrapp'], dtype=object)}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionnaire_learningrate_epoch\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "floating-republic",
   "metadata": {},
   "source": [
    "contenu du dictionnaire:\n",
    "    dictionnaire_learningrate_epoch:\n",
    "\n",
    "{'learning_rate0.01 epoch 5': {'Précision train': 0.25784728,\n",
    "  'Précision test': 0.090384625,\n",
    "  'AUC train': 0.8703303,\n",
    "  'AUC test': 0.8024738,\n",
    "  'Temps': 10.245213031768799,\n",
    "  'Recommandation': array(['Lady Gaga', 'Britney Spears', 'Rihanna', 'Katy Perry', 'Madonna',\n",
    "         'Paramore', 'The Beatles', 'Avril Lavigne', 'Christina Aguilera',\n",
    "         'Beyoncé'], dtype=object)},\n",
    " 'learning_rate0.01 epoch 10': {'Précision train': 0.28054082,\n",
    "  'Précision test': 0.098023504,\n",
    "  'AUC train': 0.887231,\n",
    "  'AUC test': 0.80903226,\n",
    "  'Temps': 10.064653158187866,\n",
    "  'Recommandation': array(['Lady Gaga', 'Britney Spears', 'The Beatles', 'Rihanna', 'Muse',\n",
    "         'Katy Perry', 'Madonna', 'Christina Aguilera', 'Paramore',\n",
    "         'Avril Lavigne'], dtype=object)},\n",
    " 'learning_rate0.01 epoch 15': {'Précision train': 0.2828738,\n",
    "  'Précision test': 0.09476496,\n",
    "  'AUC train': 0.8960393,\n",
    "  'AUC test': 0.81631577,\n",
    "  'Temps': 10.277898788452148,\n",
    "  'Recommandation': array(['Lady Gaga', 'Britney Spears', 'Madonna', 'Rihanna', 'The Beatles',\n",
    "         'Beyoncé', 'Christina Aguilera', 'Katy Perry', 'Avril Lavigne',\n",
    "         'Muse'], dtype=object)},\n",
    " 'learning_rate0.05 epoch 5': {'Précision train': 0.35212088,\n",
    "  'Précision test': 0.12259615,\n",
    "  'AUC train': 0.940019,\n",
    "  'AUC test': 0.84453136,\n",
    "  'Temps': 10.235884189605713,\n",
    "  'Recommandation': array(['Muse', 'Depeche Mode', 'The Beatles', 'Coldplay', 'The Cure',\n",
    "         'The Killers', 'Radiohead', 'Green Day', 'Arctic Monkeys',\n",
    "         'Madonna'], dtype=object)},\n",
    " 'learning_rate0.05 epoch 10': {'Précision train': 0.3906151,\n",
    "  'Précision test': 0.13798077,\n",
    "  'AUC train': 0.96736825,\n",
    "  'AUC test': 0.8606081,\n",
    "  'Temps': 11.957024335861206,\n",
    "  'Recommandation': array(['Madonna', 'Depeche Mode', 'Michael Jackson', 'Duran Duran',\n",
    "         'a-ha', 'Lady Gaga', 'Pet Shop Boys', 'New Order', 'Björk',\n",
    "         'The Beatles'], dtype=object)},\n",
    " 'learning_rate0.05 epoch 15': {'Précision train': 0.4016967,\n",
    "  'Précision test': 0.13851497,\n",
    "  'AUC train': 0.97656006,\n",
    "  'AUC test': 0.8660231,\n",
    "  'Temps': 10.265170335769653,\n",
    "  'Recommandation': array(['The Beatles', 'Madonna', 'Radiohead', 'Depeche Mode', 'Björk',\n",
    "         'Daft Punk', 'Muse', 'U2', 'Michael Jackson', 'Goldfrapp'],\n",
    "        dtype=object)},\n",
    " 'learning_rate0.1 epoch 5': {'Précision train': 0.3480382,\n",
    "  'Précision test': 0.11565172,\n",
    "  'AUC train': 0.96538705,\n",
    "  'AUC test': 0.8351683,\n",
    "  'Temps': 9.622056484222412,\n",
    "  'Recommandation': array(['The Cure', 'Radiohead', 'Sigur Rós', 'Depeche Mode', 'New Order',\n",
    "         'Dave Gahan', 'Björk', 'a-ha', 'The Beatles', 'Camouflage'],\n",
    "        dtype=object)},\n",
    " 'learning_rate0.1 epoch 10': {'Précision train': 0.37545067,\n",
    "  'Précision test': 0.122435905,\n",
    "  'AUC train': 0.9834084,\n",
    "  'AUC test': 0.8440251,\n",
    "  'Temps': 9.580250024795532,\n",
    "  'Recommandation': array(['Depeche Mode', 'a-ha', 'The Beatles', 'Pet Shop Boys', 'Placebo',\n",
    "         'Bauhaus', 'Led Zeppelin', 'The Cure', 'Duran Duran', 'Nirvana'],\n",
    "        dtype=object)},\n",
    " 'learning_rate0.1 epoch 15': {'Précision train': 0.37672323,\n",
    "  'Précision test': 0.12361112,\n",
    "  'AUC train': 0.98758894,\n",
    "  'AUC test': 0.84682965,\n",
    "  'Temps': 9.732582807540894,\n",
    "  'Recommandation': array(['Röyksopp', 'Madonna', 'Orchestral Manoeuvres in the Dark',\n",
    "         'Erasure', 'Glee Cast', 'Dido', 'Depeche Mode', 'Bat for Lashes',\n",
    "         'Pet Shop Boys', 'Goldfrapp'], dtype=object)}}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "secondary-andrew",
   "metadata": {},
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "premier-corrections",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Méthode warp:\n",
      "Precision: train 0.26, test 0.09.\n",
      "AUC: train 0.87, test 0.80.\n",
      "Recommandation:\n",
      "['Lady Gaga' 'Britney Spears' 'Rihanna' 'Katy Perry' 'Madonna' 'Paramore'\n",
      " 'The Beatles' 'Avril Lavigne' 'Christina Aguilera' 'Beyoncé']\n",
      "\n",
      "Méthode warp:\n",
      "Precision: train 0.28, test 0.10.\n",
      "AUC: train 0.89, test 0.81.\n",
      "Recommandation:\n",
      "['Lady Gaga' 'Britney Spears' 'The Beatles' 'Rihanna' 'Muse' 'Katy Perry'\n",
      " 'Madonna' 'Christina Aguilera' 'Paramore' 'Avril Lavigne']\n",
      "\n",
      "Méthode warp:\n",
      "Precision: train 0.28, test 0.09.\n",
      "AUC: train 0.90, test 0.82.\n",
      "Recommandation:\n",
      "['Lady Gaga' 'Britney Spears' 'Madonna' 'Rihanna' 'The Beatles' 'Beyoncé'\n",
      " 'Christina Aguilera' 'Katy Perry' 'Avril Lavigne' 'Muse']\n",
      "\n",
      "Méthode warp:\n",
      "Precision: train 0.35, test 0.12.\n",
      "AUC: train 0.94, test 0.84.\n",
      "Recommandation:\n",
      "['Muse' 'Depeche Mode' 'The Beatles' 'Coldplay' 'The Cure' 'The Killers'\n",
      " 'Radiohead' 'Green Day' 'Arctic Monkeys' 'Madonna']\n",
      "\n",
      "Méthode warp:\n",
      "Precision: train 0.39, test 0.14.\n",
      "AUC: train 0.97, test 0.86.\n",
      "Recommandation:\n",
      "['Madonna' 'Depeche Mode' 'Michael Jackson' 'Duran Duran' 'a-ha'\n",
      " 'Lady Gaga' 'Pet Shop Boys' 'New Order' 'Björk' 'The Beatles']\n",
      "\n",
      "Méthode warp:\n",
      "Precision: train 0.40, test 0.14.\n",
      "AUC: train 0.98, test 0.87.\n",
      "Recommandation:\n",
      "['The Beatles' 'Madonna' 'Radiohead' 'Depeche Mode' 'Björk' 'Daft Punk'\n",
      " 'Muse' 'U2' 'Michael Jackson' 'Goldfrapp']\n",
      "\n",
      "Méthode warp:\n",
      "Precision: train 0.35, test 0.12.\n",
      "AUC: train 0.97, test 0.84.\n",
      "Recommandation:\n",
      "['The Cure' 'Radiohead' 'Sigur Rós' 'Depeche Mode' 'New Order'\n",
      " 'Dave Gahan' 'Björk' 'a-ha' 'The Beatles' 'Camouflage']\n",
      "\n",
      "Méthode warp:\n",
      "Precision: train 0.38, test 0.12.\n",
      "AUC: train 0.98, test 0.84.\n",
      "Recommandation:\n",
      "['Depeche Mode' 'a-ha' 'The Beatles' 'Pet Shop Boys' 'Placebo' 'Bauhaus'\n",
      " 'Led Zeppelin' 'The Cure' 'Duran Duran' 'Nirvana']\n",
      "\n",
      "Méthode warp:\n",
      "Precision: train 0.38, test 0.12.\n",
      "AUC: train 0.99, test 0.85.\n",
      "Recommandation:\n",
      "['Röyksopp' 'Madonna' 'Orchestral Manoeuvres in the Dark' 'Erasure'\n",
      " 'Glee Cast' 'Dido' 'Depeche Mode' 'Bat for Lashes' 'Pet Shop Boys'\n",
      " 'Goldfrapp']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(resultats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-northwest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "talented-battlefield",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "starting-prophet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-certificate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-allocation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-essence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-belize",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-silicon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-password",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "velvet-villa",
   "metadata": {},
   "source": [
    "\n",
    "# Recommander Systems\n",
    "\n",
    "Construire, comprendre et tuner un système de recommandation.\n",
    "\n",
    "# Description\n",
    "\n",
    "## Familarisation\n",
    "\n",
    "Les systèmes de recommandations sont utilisé traditionnellement et comme le nom l'indique pour recommander du contenu à des utilisateurs.\n",
    "Par exemple pour recommander un film à des utilisateurs en fonctions de ceux qu'ils ont vue, ou de la musique, ou des vidéos ou encore implémenter des fonctionnalités \"more like this\".\n",
    "\n",
    "Nous allons commencer par suivre et reproduire les étapes de ce tuto: \n",
    "\n",
    "*  https://www.datacamp.com/community/tutorials/recommender-systems-python\n",
    "\n",
    "En assumant que vous avez peu de RAM, nous allons nous arrêter au moment de calculer la  `compute_sim` variable.\n",
    "\n",
    "\n",
    "**step1 : simple recommander**\n",
    "Quelle est la complexité en mémoire de cette opération ?\n",
    "(utiliser cosine_similarity qui utilise moins de mémoire (quand même 8Go, possible sur collab)\n",
    "Cela rentre t'il sur votre machine ?\n",
    "\n",
    "Qu'essaye de faire l'auteur avec ce calcul ?\n",
    "Comment pouvons-nous contourner ce problème ?\n",
    "\n",
    "\n",
    "**step2 : content based recommander**\n",
    "\n",
    "implémenter la deuxiéme partie en évitant le produit de matrice.\n",
    "\n",
    "**step3 : amélioration**\n",
    "\n",
    "coder les 2 améliorations :\n",
    "1. Introduce a popularity filter: this recommender would take the 30 most similar movies, calculate the weighted ratings (using the IMDB formula from above), sort movies based on this rating, and return the top 10 movies.\n",
    "2. Use the PCA to improve the speed of your similarity search with 100 components. Does the result are coherent.\n",
    "\n",
    "\n",
    "## LastFM Project\n",
    "\n",
    "M. Pontier vous contact pour l'aider à construire un système de recommandation. Il dispose d'une base de données comportant des données concernant ses utilisateurs (anonymisé) contenant les artistes qu'ils écoutent sur sa plateforme ainsi que le nombre d'écoutes. Monsieur pontier souhaite recommander à ses utilisateur  des artistes qu'il n'ont pas encore écoutés, et cela en fonction de leurs préférences musicale.\n",
    "\n",
    "Monsieur pontier souhaite utiliser la librairie Lightfm, avec laquelle il a déjà un driver permettant de charger ses données qu'il vous fournit, un vrai bonus.\n",
    "Monsieur Pontier à pu voir que la documentation comporte plusieurs modèle, il souhaite évaluer les modèle sur une jeux de train/test et utiliser le meilleurs modéle.\n",
    "\n",
    "Pour l'évaluation, il souhaite comparer la mesure AUC, la précision et le rappel (visiter la documentation de Lightfm), qui devront être présenté dans un tableau.\n",
    "\n",
    "\n",
    "#### Bonus 1\n",
    "\n",
    "Comparer les résulats de l'AUC avec le meilleurs modéle de lightfm et une PCA (TruncatedSDV).\n",
    "\n",
    "\n",
    "#### Bonus 2\n",
    "\n",
    "L'apprentissage devant être le plus rapide possible tout en obtenant les meilleurs résultats, il vous est demandé de trouver le nombre d'itération permettant d'atteindre la convergence de 95% de la valeur maximal d'AUC sur le jeux de test.\n",
    "\n",
    "\n",
    "### Veille\n",
    "\n",
    "Quelle système de recommandation allez vous mettre en place ?\n",
    "\n",
    "Qu'est ce que Lightfm ?\n",
    "\n",
    "Qu'est ce un système de recommandation dit à \"implicit feedback\" ? Et a \"explicit feedback ?\n",
    "\n",
    "\n",
    "### Ressources: \n",
    "\n",
    "* LightFM: https://github.com/lyst/lightfm\n",
    "* Jeux de données Last.fm : https://grouplens.org/datasets/hetrec-2011/\n",
    "* https://towardsdatascience.com/recommendation-system-in-python-lightfm-61c85010ce17\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-saudi",
   "metadata": {},
   "source": [
    "# Bout de code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fewer-stability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Artiste  id\n",
      "0    toto  10\n",
      "1    titi  11\n",
      "2    tutu  12\n",
      "3    tyty  13\n",
      "4    tata  14\n",
      "5    tete  15\n",
      "  Utilisateur  id\n",
      "0      d2toto  10\n",
      "1      d2titi  11\n",
      "2      d2tutu  12\n",
      "3      d2tyty  13\n",
      "4      d2tata  14\n",
      "5      d2tete  15\n"
     ]
    }
   ],
   "source": [
    "data1= np.array([[\"toto\",\"titi\",\"tutu\",\"tyty\",\"tata\",\"tete\"],[10,11,12,13,14,15]]).T\n",
    "df1= pd.DataFrame(data1, columns=[\"Artiste\",\"id\"])\n",
    "print(df1)\n",
    "data2= np.array([[\"d2toto\",\"d2titi\",\"d2tutu\",\"d2tyty\",\"d2tata\",\"d2tete\"],[10,11,12,13,14,15]]).T\n",
    "df2= pd.DataFrame(data2, columns=[\"Utilisateur\",\"id\"])\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "commercial-sending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artiste</th>\n",
       "      <th>id</th>\n",
       "      <th>Utilisateur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toto</td>\n",
       "      <td>10</td>\n",
       "      <td>d2toto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>titi</td>\n",
       "      <td>11</td>\n",
       "      <td>d2titi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tutu</td>\n",
       "      <td>12</td>\n",
       "      <td>d2tutu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tyty</td>\n",
       "      <td>13</td>\n",
       "      <td>d2tyty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tata</td>\n",
       "      <td>14</td>\n",
       "      <td>d2tata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tete</td>\n",
       "      <td>15</td>\n",
       "      <td>d2tete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Artiste  id Utilisateur\n",
       "0    toto  10      d2toto\n",
       "1    titi  11      d2titi\n",
       "2    tutu  12      d2tutu\n",
       "3    tyty  13      d2tyty\n",
       "4    tata  14      d2tata\n",
       "5    tete  15      d2tete"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1df2 = pd.merge(df1, df2, how=\"inner\")\n",
    "df1df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-prompt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
